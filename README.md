# Spark-ETL
Spark ETL
Datalake project for sparkify using Spark.

Getting Started
These instructions will get you a copy of the project up and running on your local machine for development and testing purposes. See deployment for notes on how to deploy the project on a live system.

Prerequisites
What things you need to install:

Libraries
configparser
datetime
os
pandas
pyspark.sql(
from pyspark.sql import SparkSession as SS
from pyspark.sql.functions import udf, col
from pyspark.sql.functions import year, month, dayofmonth, hour, weekofyear, date_format
from pyspark.sql.functions import monotonically_increasing_id)

Tools
Python3(3.6+)
Spyder(Anaconda for testing although can use Jypter)
Cup of coffee


Running the tests
Pytest but this has not yet been set up.


Versioning
N/A

Authors
Mahdi Mostafa - Initial work

License
This project is licensed under the MIT License - see the LICENSE.md file for details
